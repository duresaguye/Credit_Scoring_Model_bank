{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ngoU4RFwHZ_q"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Load the saved data\n",
        "data = pd.read_csv(\"processed_rfms_data.csv\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle missing values\n",
        "data.fillna(data.median(numeric_only=True), inplace=True)\n",
        "\n",
        "# Encode categorical variables\n",
        "categorical_cols = data.select_dtypes(include=['object']).columns\n",
        "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
        "encoded_data = pd.DataFrame(encoder.fit_transform(data[categorical_cols]),\n",
        "                            columns=encoder.get_feature_names_out(categorical_cols),\n",
        "                            index=data.index)"
      ],
      "metadata": {
        "id": "XZac5RJlMFiO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop categorical columns and reset index\n",
        "data_dropped = data.drop(columns=categorical_cols).reset_index(drop=True)\n",
        "\n",
        "# Reset index of encoded data\n",
        "encoded_data = encoded_data.reset_index(drop=True)\n",
        "\n",
        "# Ensure row counts match\n",
        "if data_dropped.shape[0] != encoded_data.shape[0]:\n",
        "    raise ValueError(\"Mismatch in row count between data and encoded_data\")\n",
        "\n",
        "# Merge the datasets\n",
        "data = pd.concat([data_dropped, encoded_data], axis=1)\n",
        "\n",
        "# Verify the shape of the resulting dataset\n",
        "print(f\"Final dataset shape: {data.shape}\")\n"
      ],
      "metadata": {
        "id": "_0Yna2yNRA_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the encoded categorical data back into the dataset\n",
        "data = pd.concat([data.drop(columns=categorical_cols), encoded_data], axis=1)"
      ],
      "metadata": {
        "id": "o52bO9HtMkLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Sn07kJdLLX8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the target and features\n",
        "X = data.drop(columns=['DefaultLabel'])  # Features\n",
        "y = data['DefaultLabel']  # Target (Good/Bad classification)\n",
        "\n",
        "# Encode target labels (if not already numerical)\n",
        "y = y.map({'Good': 1, 'Bad': 0})  # Convert to binary format\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
        "}"
      ],
      "metadata": {
        "id": "EN_-R9TiKtEh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
        "}\n"
      ],
      "metadata": {
        "id": "UhGPmBZlKx8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter Tuning for Random Forest (example)\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "print(\"\\nHyperparameter tuning for Random Forest...\")\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=RandomForestClassifier(random_state=42),\n",
        "    param_grid=param_grid,\n",
        "    scoring='roc_auc',\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "ufuR71A8LC95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best parameters and performance\n",
        "best_rf = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "best_roc_auc = grid_search.best_score_\n",
        "\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(f\"Best ROC-AUC Score: {best_roc_auc}\")\n",
        "\n",
        "# Save results to CSV\n",
        "results_df = pd.DataFrame(results).T\n",
        "results_df.to_csv(\"model_performance_metrics.csv\", index=True)\n",
        "\n",
        "print(\"\\nModel performance metrics saved to 'model_performance_metrics.csv'\")"
      ],
      "metadata": {
        "id": "roeY9KlTLP3t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}