{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngoU4RFwHZ_q",
        "outputId": "3433130d-dc56-4f28-d2f2-4cfdbe471b3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Logistic Regression...\n",
            "Logistic Regression Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     18597\n",
            "           1       1.00      1.00      1.00     10102\n",
            "\n",
            "    accuracy                           1.00     28699\n",
            "   macro avg       1.00      1.00      1.00     28699\n",
            "weighted avg       1.00      1.00      1.00     28699\n",
            "\n",
            "\n",
            "Training Decision Tree...\n",
            "Decision Tree Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     18597\n",
            "           1       1.00      1.00      1.00     10102\n",
            "\n",
            "    accuracy                           1.00     28699\n",
            "   macro avg       1.00      1.00      1.00     28699\n",
            "weighted avg       1.00      1.00      1.00     28699\n",
            "\n",
            "\n",
            "Training Random Forest...\n",
            "Random Forest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     18597\n",
            "           1       1.00      1.00      1.00     10102\n",
            "\n",
            "    accuracy                           1.00     28699\n",
            "   macro avg       1.00      1.00      1.00     28699\n",
            "weighted avg       1.00      1.00      1.00     28699\n",
            "\n",
            "\n",
            "Training Gradient Boosting...\n",
            "Gradient Boosting Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     18597\n",
            "           1       1.00      1.00      1.00     10102\n",
            "\n",
            "    accuracy                           1.00     28699\n",
            "   macro avg       1.00      1.00      1.00     28699\n",
            "weighted avg       1.00      1.00      1.00     28699\n",
            "\n",
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
            "\n",
            "Best Parameters: {'classifier__max_depth': None, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 100}\n",
            "Best ROC-AUC: 1.000\n",
            "\n",
            "Results saved to 'model_performance_metrics.csv'\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "\n",
        "# Load data\n",
        "data = pd.read_csv(\"processed_rfms_data.csv\")\n",
        "\n",
        "# ==================================================================\n",
        "# STEP 1: Define the Target Variable\n",
        "# ==================================================================\n",
        "# Option 1: If 'DefaultLabel' already exists in the CSV (Good/Bad labels):\n",
        "# data['DefaultLabel'] = data['DefaultLabel'].map({'Good': 1, 'Bad': 0})\n",
        "\n",
        "# Option 2: Create target based on Amount threshold (example):\n",
        "data['DefaultLabel'] = (data['Amount'] > 1000).astype(int)\n",
        "\n",
        "# ==================================================================\n",
        "# STEP 2: Split Data FIRST to Avoid Data Leakage\n",
        "# ==================================================================\n",
        "X = data.drop(columns=['DefaultLabel'])\n",
        "y = data['DefaultLabel']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# ==================================================================\n",
        "# STEP 3: Preprocessing Pipeline\n",
        "# ==================================================================\n",
        "# Identify categorical columns\n",
        "categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Custom function to bucket rare categories using TRAINING DATA\n",
        "def bucket_rare_categories(X, top_n=20):\n",
        "    X_processed = X.copy()\n",
        "    for col in X_processed.select_dtypes(include=['object']).columns:\n",
        "        top_cats = X_processed[col].value_counts().nlargest(top_n).index\n",
        "        X_processed[col] = X_processed[col].where(X_processed[col].isin(top_cats), 'Other')\n",
        "    return X_processed\n",
        "\n",
        "# Preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('categorical', Pipeline(steps=[\n",
        "            ('bucket', FunctionTransformer(bucket_rare_categories, kw_args={'top_n': 20})),\n",
        "            ('frequency_encoder', FunctionTransformer(\n",
        "                lambda X: X.apply(lambda col: col.map(col.value_counts(normalize=True))),\n",
        "                validate=False\n",
        "            ))\n",
        "        ]), categorical_cols)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# ==================================================================\n",
        "# STEP 4: Model Training & Evaluation\n",
        "# ==================================================================\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    # Create a pipeline with preprocessing and model\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', model)\n",
        "    ])\n",
        "\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "    y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Metrics\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred, zero_division=0),\n",
        "        \"Recall\": recall_score(y_test, y_pred, zero_division=0),\n",
        "        \"F1\": f1_score(y_test, y_pred, zero_division=0),\n",
        "        \"ROC-AUC\": roc_auc_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    results[name] = metrics\n",
        "    print(f\"{name} Classification Report:\\n{classification_report(y_test, y_pred)}\")\n",
        "\n",
        "# ==================================================================\n",
        "# STEP 5: Hyperparameter Tuning (Random Forest Example)\n",
        "# ==================================================================\n",
        "# Full pipeline with hyperparameter tuning\n",
        "rf_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'classifier__n_estimators': [100, 200],\n",
        "    'classifier__max_depth': [None, 15, 30],\n",
        "    'classifier__min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=rf_pipeline,\n",
        "    param_grid=param_grid,\n",
        "    scoring='roc_auc',\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best model\n",
        "best_rf = grid_search.best_estimator_\n",
        "print(f\"\\nBest Parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best ROC-AUC: {grid_search.best_score_:.3f}\")\n",
        "\n",
        "# ==================================================================\n",
        "# STEP 6: Save Results\n",
        "# ==================================================================\n",
        "results_df = pd.DataFrame(results).T\n",
        "results_df.to_csv(\"model_performance_metrics.csv\", index=True)\n",
        "print(\"\\nResults saved to 'model_performance_metrics.csv'\")"
      ]
    }
  ]
}